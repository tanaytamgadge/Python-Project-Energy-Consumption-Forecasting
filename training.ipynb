{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pi7ROVMreMik"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "\n",
        "# Load preprocessed dataset (Assuming it's already preprocessed and ready)\n",
        "data = pd.read_csv(\"energy_consumption_preprocessed.csv\")\n",
        "\n",
        "# Feature selection (can customize based on data)\n",
        "features = ['Temperature', 'Humidity', 'Wind Speed', 'Hour', 'Day', 'Weekday', 'Month', 'Holiday_1', 'Season_Summer', 'Season_Winter']\n",
        "target = 'Consumption'\n",
        "\n",
        "X = data[features]\n",
        "y = data[target]\n",
        "\n",
        "# Split the dataset into training and testing sets (80-20 split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardizing the features using StandardScaler (important for linear models)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Model initialization for Linear Regression and Random Forest Regressor\n",
        "regressor_lr = LinearRegression()\n",
        "regressor_rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Training the Linear Regression model\n",
        "print(\"Training the Linear Regression model...\")\n",
        "regressor_lr.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Hyperparameter tuning using GridSearchCV for Random Forest Regressor\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [10, 20, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "print(\"Tuning Random Forest Regressor...\")\n",
        "grid_search_rf = GridSearchCV(estimator=regressor_rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
        "grid_search_rf.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Best parameters for Random Forest\n",
        "print(f\"Best parameters for Random Forest: {grid_search_rf.best_params_}\")\n",
        "\n",
        "# Model performance on the test set (Linear Regression)\n",
        "y_pred_lr = regressor_lr.predict(X_test_scaled)\n",
        "print(f\"Linear Regression Model Performance:\")\n",
        "print(f\"R^2 Score: {r2_score(y_test, y_pred_lr):.4f}\")\n",
        "print(f\"Mean Squared Error (MSE): {mean_squared_error(y_test, y_pred_lr):.4f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {np.sqrt(mean_squared_error(y_test, y_pred_lr)):.4f}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mean_absolute_error(y_test, y_pred_lr):.4f}\")\n",
        "\n",
        "# Predictions from Random Forest with the best parameters\n",
        "y_pred_rf = grid_search_rf.predict(X_test_scaled)\n",
        "print(f\"Random Forest Model Performance:\")\n",
        "print(f\"R^2 Score: {r2_score(y_test, y_pred_rf):.4f}\")\n",
        "print(f\"Mean Squared Error (MSE): {mean_squared_error(y_test, y_pred_rf):.4f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {np.sqrt(mean_squared_error(y_test, y_pred_rf)):.4f}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mean_absolute_error(y_test, y_pred_rf):.4f}\")\n",
        "\n",
        "# Comparing Linear Regression and Random Forest Model Predictions\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Actual': y_test,\n",
        "    'Predicted LR': y_pred_lr,\n",
        "    'Predicted RF': y_pred_rf\n",
        "})\n",
        "\n",
        "print(comparison_df.head())\n",
        "\n",
        "# Saving the model predictions to CSV\n",
        "comparison_df.to_csv(\"model_comparison_predictions.csv\", index=False)\n",
        "\n",
        "# Visualizing Actual vs Predicted Values for Linear Regression\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(y_test.values, label='Actual Consumption', color='blue', linewidth=2)\n",
        "plt.plot(y_pred_lr, label='Predicted Consumption (Linear Regression)', color='red', linestyle='dashed', linewidth=2)\n",
        "plt.title('Actual vs Predicted Energy Consumption (Linear Regression)')\n",
        "plt.xlabel('Data Points')\n",
        "plt.ylabel('Consumption (kWh)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Visualizing Actual vs Predicted Values for Random Forest\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(y_test.values, label='Actual Consumption', color='blue', linewidth=2)\n",
        "plt.plot(y_pred_rf, label='Predicted Consumption (Random Forest)', color='green', linestyle='dashed', linewidth=2)\n",
        "plt.title('Actual vs Predicted Energy Consumption (Random Forest)')\n",
        "plt.xlabel('Data Points')\n",
        "plt.ylabel('Consumption (kWh)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Saving the trained models using pickle\n",
        "with open('linear_regression_model.pkl', 'wb') as lr_file:\n",
        "    pickle.dump(regressor_lr, lr_file)\n",
        "\n",
        "with open('random_forest_model.pkl', 'wb') as rf_file:\n",
        "    pickle.dump(grid_search_rf.best_estimator_, rf_file)\n",
        "\n",
        "with open('scaler.pkl', 'wb') as scaler_file:\n",
        "    pickle.dump(scaler, scaler_file)\n",
        "\n",
        "print(\"Models and scaler saved successfully!\")\n",
        "\n",
        "# Error Analysis (Residuals)\n",
        "errors_lr = y_pred_lr - y_test.values\n",
        "errors_rf = y_pred_rf - y_test.values\n",
        "\n",
        "print(f\"Linear Regression - Mean error: {np.mean(errors_lr)}\")\n",
        "print(f\"Random Forest - Mean error: {np.mean(errors_rf)}\")\n",
        "\n",
        "# Residual analysis for Linear Regression\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(errors_lr, kde=True, color='purple', label=\"LR Residuals\")\n",
        "sns.histplot(errors_rf, kde=True, color='orange', label=\"RF Residuals\")\n",
        "plt.title('Residuals Distribution')\n",
        "plt.xlabel('Prediction Error (kWh)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Residuals vs Predicted values plot for both models\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(y_pred_lr, errors_lr, color='purple', alpha=0.5)\n",
        "plt.axhline(y=0, color='black', linestyle='--')\n",
        "plt.title('Residuals vs Predicted Values (Linear Regression)')\n",
        "plt.xlabel('Predicted Values (Linear Regression)')\n",
        "plt.ylabel('Residuals')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(y_pred_rf, errors_rf, color='orange', alpha=0.5)\n",
        "plt.axhline(y=0, color='black', linestyle='--')\n",
        "plt.title('Residuals vs Predicted Values (Random Forest)')\n",
        "plt.xlabel('Predicted Values (Random Forest)')\n",
        "plt.ylabel('Residuals')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Cross-Validation Score (for Linear Regression and Random Forest)\n",
        "cv_score_lr = cross_val_score(regressor_lr, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
        "cv_score_rf = cross_val_score(grid_search_rf.best_estimator_, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "print(f\"Cross-Validation Score (Linear Regression): {np.mean(cv_score_lr):.4f}\")\n",
        "print(f\"Cross-Validation Score (Random Forest): {np.mean(cv_score_rf):.4f}\")\n",
        "\n",
        "# Hyperparameter tuning for Linear Regression  - Ridge or Lasso\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "ridge = Ridge(alpha=1.0)\n",
        "ridge.fit(X_train_scaled, y_train)\n",
        "y_pred_ridge = ridge.predict(X_test_scaled)\n",
        "\n",
        "print(f\"Ridge Regression Model Performance:\")\n",
        "print(f\"R^2 Score: {r2_score(y_test, y_pred_ridge):.4f}\")\n",
        "print(f\"Mean Squared Error (MSE): {mean_squared_error(y_test, y_pred_ridge):.4f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {np.sqrt(mean_squared_error(y_test, y_pred_ridge)):.4f}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mean_absolute_error(y_test, y_pred_ridge):.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
